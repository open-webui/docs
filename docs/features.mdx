---
sidebar_position: 4
title: "â­ Features"
---

import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Key Features of Open WebUI â­

- ğŸš€ **Effortless Setup**: Install seamlessly using Docker or Kubernetes (`kubectl`, `kustomize` or `helm`) for a hassle-free experience with support for both `:ollama` and `:cuda` tagged images.

- ğŸ¤ **OpenAI API Integration**: Effortlessly integrate OpenAI-compatible APIs for versatile conversations alongside Ollama models. The OpenAI API URL can be customized to link with various third-party applications.

- ğŸ“± **Responsive Design**: Enjoy a seamless experience across desktop PCs, laptops, and mobile devices.

- ğŸ“± **Progressive Web App for Mobile**: Enjoy a native progressive web application experience on your mobile device with offline access on `localhost` or a personal domain, and a smooth user interface. In order for our PWA to be installable on your device, it must be delivered in a secure context. This usually means that it must be served over HTTPS.
  - To set up a PWA, you'll need some understanding of technologies like Linux, Docker, and reverse proxies such as `Nginx`, `Caddy`, or `Traefik`. Using these tools can help streamline the process of building and deploying a PWA tailored to your needs. While there's no "one-click install" option available, and your available option to securely deploy your Open WebUI instance over HTTPS requires user experience, using these resources can make it easier to create and deploy a PWA tailored to your needs.

- âœ’ï¸ğŸ”¢ **Full Markdown and LaTeX Support**: Elevate your LLM experience with comprehensive Markdown and LaTeX capabilities for enriched interaction.

- ğŸ§© **Model Builder**: Easily create Ollama models directly from Open WebUI. Create and add custom characters/agents, customize chat elements, and import models effortlessly through [Open WebUI Community](https://openwebui.com/) integration.

- ğŸ“š **Local and Remote RAG Integration**: Dive into the future of chat interactions and explore your documents with our cutting-edge Retrieval Augmented Generation (RAG) technology within your chats. Documents can be loaded into the workspace area, after which they can be accessed using the `#` symbol before a query, or by starting the prompt with `#`, followed by a URL for web content integration.

- ğŸ” **Web Search for RAG**: You can perform web searches using a selection of various search providers and inject the results directly into your local Retrieval Augmented Generation (RAG) experience.

- ğŸŒ **Web Browsing Capabilities**: Integrate websites seamlessly into your chat experience by using the `#` command followed by a URL. This feature enables the incorporation of web content directly into your conversations, thereby enhancing the richness and depth of your interactions.

- ğŸ¨ **Image Generation Integration**: Seamlessly incorporate image generation capabilities to enrich your chat experience with dynamic visual content.

- âš™ï¸ **Concurrent Model Utilization**: Effortlessly engage with multiple models simultaneously, harnessing their unique strengths for optimal responses. Leverage a diverse set of model modalities in parallel to enhance your experience.

- ğŸ” **Role-Based Access Control (RBAC)**: Ensure secure access with restricted permissions;. Only authorized individuals can access your Ollama, while model creation and pulling rights are exclusively reserved for administrators.

- ğŸŒğŸŒ **Multilingual Support**: Experience Open WebUI in your preferred language with our internationalization (`i18n`) support. We invite you to join us in expanding our supported languages! We're actively seeking contributors!

- ğŸŒŸ **Continuous Updates**: We are committed to improving Open WebUI with regular updates, fixes, and new features.

## And many more remarkable features including... âš¡ï¸

---

### ğŸ”§ Pipelines Support

- ğŸ”§ **Pipelines Framework**: Seamlessly integrate and customize your Open WebUI experience with our modular plugin framework for enhanced customization and functionality (https://github.com/open-webui/pipelines). Our framework allows for the easy addition of custom logic and integration of Python libraries, from AI agents to home automation APIs.

- ğŸ“¥ **Upload Pipeline**: Pipelines can be uploaded directly from the `Admin Panel` > `Settings` > `Pipelines` section, streamlining the pipeline management process.

#### The possibilities with our Pipelines framework knows no bounds and are practically limitless. Start with a few pre-built pipelines to help you get started!

- ğŸ”— **Function Calling**: Integrate [Function Calling](https://github.com/open-webui/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py) seamlessly through Pipelines to enhance your LLM interactions with advanced function calling capabilities.

- ğŸ“š **Custom RAG**: Integrate a [custom Retrieval Augmented Generation (RAG)](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/rag) pipeline seamlessly to enhance your LLM interactions with custom RAG logic.

- ğŸ“Š **Message Monitoring with Langfuse**: Monitor and analyze message interactions in real-time usage statistics via [Langfuse](https://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py) pipeline.

- âš–ï¸ **User Rate Limiting**: Manage API usage efficiently by controlling the flow of requests sent to LLMs to prevent exceeding rate limits with [Rate Limit](https://github.com/open-webui/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py) pipeline.

- ğŸŒ **Real-Time LibreTranslate Translation**: Integrate real-time translations into your LLM interactions using [LibreTranslate](https://github.com/open-webui/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py) pipeline, enabling cross-lingual communication.
 - Please note that this pipeline requires further setup with LibreTranslate in a Docker container to work.

- ğŸ›¡ï¸ **Toxic Message Filtering**: Our [Detoxify](https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py) pipeline automatically filters out toxic messages to maintain a clean and safe chat environment.

- ğŸ”’ **LLM-Guard**: Ensure secure LLM interactions with [LLM-Guard](https://github.com/open-webui/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py) pipeline, featuring a Prompt Injection Scanner that detects and mitigates crafty input manipulations targeting large language models. This protects your LLMs from data leakage and adds a layer of resistance against prompt injection attacks.

- ğŸ•’ **Conversation Turn Limits**: Improve interaction management by setting limits on conversation turns with [Conversation Turn Limit](https://github.com/open-webui/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py) pipeline.

- ğŸ“ˆ **OpenAI Generation Stats**: Our [OpenAI](https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py) pipeline provides detailed generation statistics for OpenAI models.

- **ğŸš€ Multi-Model Support**: Our seamless integration with various AI models from [various providers](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/providers) expands your possibilities with a wide range of language models to select from and interact with.

#### In addition to the extensive features and customization options, we also provide [a library of example pipelines ready to use](https://github.com/open-webui/pipelines/tree/main/examples) along with [a practical example scaffold pipeline](https://github.com/open-webui/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py) to help you get started. These resources will streamline your development process and enable you to quickly create powerful LLM interactions using Pipelines and Python. Happy coding! ğŸ’¡

---

### ğŸ–¥ï¸ User Experience

- ğŸ–¥ï¸ **Intuitive Interface**: The chat interface has been designed with the user in mind, drawing inspiration from the user interface of ChatGPT.

- âš¡ **Swift Responsiveness**: Enjoy reliably fast and responsive performance.

- ğŸ¨ **Splash Screen**: A simple loading splash screen for a smoother user experience.

- ğŸ“¦ **Pip Install Method**: Installation of Open WebUI can be accomplished via the command `pip install open-webui`, which streamlines the process and makes it more accessible to new users. For further information, please visit: https://pypi.org/project/open-webui/.

- ğŸŒˆ **Theme Customization**: Personalize your Open WebUI experience with a range of options, including a variety of solid, yet sleek themes, customizable chat background images, and three mode options: Light, Dark, or OLED Dark mode - or let *Her* choose for you! ;)

- ğŸ’» **Code Syntax Highlighting**: Our syntax highlighting feature enhances code readability, providing a clear and concise view of your code.

- â†•ï¸ **Bi-Directional Chat Support**: You can easily switch between left-to-right and right-to-left chat directions to accommodate various language preferences.

- ğŸ“± **Mobile Accessibility**: The sidebar can be opened and closed on mobile devices with a simple swipe gesture.

- ğŸ“‚ **Unified Workspace**: A unified workspace section provides access to all your model files, prompts, documents, tools, and functions in one convenient location, streamlining your workflow.

- ğŸ’¾ **Persistent Settings**: Benefit from the convenience of saved and persistent settings within Open WebUI, stored in a config.json file for easy access and reuse.

- â“ **Quick Access to Documentation & Shortcuts**: The question mark button located at the bottom right-hand corner of the main UI screen (available on larger screens like PCs) provides users with easy access to the Open WebUI documentation page and available keyboard shortcuts.

- ğŸ“œ **Changelog & Check for Updates**: Users can access a comprehensive changelog and check for updates in `Settings` > `About` > `See What's New`, which provides a quick overview of the latest features, improvements, and bug fixes, as well as the ability to check for updates.

---

### ğŸ’¬ Conversations

- ğŸ” **RAG Embedding Support**: Change the Retrieval Augmented Generation (RAG) embedding model directly in `Admin Panel` > `Settings` > `Documents`, enhancing document processing. This feature supports Ollama and OpenAI models.

- ğŸ“œ **Citations in RAG Feature**: The Retrieval Augmented Generation (RAG) feature allows users to easily track the context of documents fed to LLMs with added citations for reference points.

- ğŸŒŸ **Enhanced RAG Pipeline**: A togglable hybrid search sub-feature for our RAG embedding feature that enhances the RAG functionality via `BM25`, with re-ranking powered by `CrossEncoder`, and configurable relevance score thresholds.

- ğŸ“¹ **YouTube RAG Pipeline**: The dedicated Retrieval Augmented Generation (RAG) pipeline for summarizing YouTube videos via video URLs enables smooth interaction with video transcriptions directly.

- ğŸ”„ **Multi-Modal Support**: Effortlessly engage with models that support multi-modal interactions, including images (`e.g., LLaVA`).

- ğŸ¤– **Multiple Model Support**: Quickly switch between different models for diverse chat interactions.

- ğŸ‘¥ **'@' Model Integration**: By seamlessly switching to any accessible local or external model during conversations, users can harness the collective intelligence of multiple models in a single chat. This can done by using the `@` command to specify the model by name within a chat.

- ğŸ·ï¸ **Conversation Tagging**: Effortlessly categorize and locate tagged chats for quick reference and streamlined data collection.

- ğŸ‘¶ **Chat Cloning**: Easily clone and save a snapshot of any chat for future reference or continuation. This feature makes it easy to pick up where you left off or share your session with others. To create a copy of your chat, simply click on the `Clone` button in the dropdown menu. Can you keep up with your clones?

- ğŸ“œ **Prompt Preset Support**: Instantly access custom preset prompts using the `/` command in the chat input. Load predefined conversation starters effortlessly and expedite your interactions. Import prompts with ease through [Open WebUI Community](https://openwebui.com/) integration or create your own!

- ğŸ“… **Prompt Variables Support**: Utilize prompt variables such as `{{CURRENT_DATE}}`, `{{CURRENT_DATETIME}}`, `{{CURRENT_TIME}}`, `{{USER_NAME}}`, and `{{USER_LOCATION}}` can be utilized in the system prompt.
  - Please note that the `{{USER_LOCATION}}` prompt variable requires a secure connection over HTTPS. To utilize this particular prompt variable, please ensure that `{{USER_LOCATION}}` is toggled on from `Settings` > `Interface`.

- ğŸ§  **Memory Feature**: Manually add information you want your LLMs to remember via `Settings` > `Personalization` > `Memory`. Memories can be added, edited, and deleted.

---

### ğŸ’» Model Management


- ğŸ› ï¸ **Model Builder**: All models can be built and edited with a persistent model builder mode within the models workspace.

- ğŸ“š **Knowledge Support for Models**: The ability to attach functions and documents directly to models from the models workspace enhances the information available to each model.

- ğŸ—‚ï¸ **Model Presets**: Create and manage model presets for both the Ollama/OpenAI API.

- ğŸ·ï¸ **Model Tagging**: The models workspace enables users to organize their models using tagging.

- ğŸ“‹ **Model Selector Dropdown Ordering**: Models can be effortlessly organized by dragging and dropping them into desired positions within the model workspace, which will then reflect the changes in the model dropdown menu.

- ğŸ” **Model Selector Dropdown**: Easily find and select your models with an included search filter and detailed model information with model tags and model descriptions.

- âš™ï¸ **Fine-Tuned Control with Advanced Parameters**: Gain a deeper level of control by adjusting model parameters such as `seed`, `temperature`, `frequency penalty`, `context length`, `seed`, and more.

- ğŸ”„ **Seamless Integration**: Copy any `ollama run {model:tag}` CLI command directly from a model's page on [Ollama library](https://ollama.com/library/) and paste it into the model dropdown to easily select and pull models.

- ğŸ—‚ï¸ **Create Ollama Modelfile**: To create a model file for Ollama, navagate to the `Admin Panel` > `Settings` > `Models` > `Create a model`.

- â¬†ï¸ **GGUF File Model Creation**: Effortlessly create Ollama models by uploading GGUF files directly from Open WebUI from `Admin Settings` > `Settings` > `Model` > `Experimental`. The process has been streamlined with the option to upload from your machine or download GGUF files from Hugging Face.

- âš™ï¸ **Default Model Setting**: The default model can be set in `Settings` > `Interface` for mobile devices, or be set easier in a new chat under the model selector dropdown on PCs.

- ğŸ’¡ **LLM Response Insights**: Details of every generated response can be viewed, including external model API insights and comprehensive local model info.

- ğŸ“¥ğŸ—‘ï¸ **Download/Delete Models**: Models can be downloaded or deleted directly from Open WebUI with ease.

- ğŸ”„ **Update All Ollama Models**: A convenient button allows users to update locally installed models in one operation, streamlining model management.

- ğŸ» **TavernAI Character Card Integration**: Experience enhanced visual storytelling with TavernAI Character Card Integration in our model builder. Users can seamlessly incorporate TavernAI character card PNGs directly into their model files, creating a more immersive and engaging user experience.

- ğŸ² **Model Playground (Beta)**: Try out models in a sandbox environment with the model playground area (`beta`), which enables users to test and explore model capabilities and settings with ease in a sandbox environment before deployment in a live chat environment.

---

### ğŸ‘¥ Collaboration

- ğŸ—¨ï¸ **Local Chat Sharing**: Generate and share chat links between users in an efficient and seamless manner, thereby enhancing collaboration and communication.

- ğŸ‘ğŸ‘ **RLHF Annotation**: Enhance the impact of your messages by rating them with either a thumbs up or thumbs down, followed by the option to provide textual feedback, facilitating the creation of datasets for Reinforcement Learning from Human Feedback (`RLHF`). Utilize your messages to train or fine-tune models, all while ensuring the confidentiality of locally saved data.

- ğŸ¤ **Community Sharing**: Share your chat sessions with the [Open WebUI Community](https://openwebui.com/) by clicking the `Share to Open WebUI Community` button. This feature allows you to engage with other users and collaborate on the platform.
  - To utilize this feature, please sign in to your Open WebUI Community account. Sharing your chats fosters a vibrant community, encourages knowledge sharing, and facilitates joint problem-solving. Please note that community sharing of chat sessions is an optional feature. Only Admins can toggle this feature on or off via the `Admin Settings` > `Settings` > `General` menu.

---

### ğŸ“š History & Archive

- ğŸ“œ **Chat History**: Access and manage your conversation history with ease via the chat navigation sidebar. Toggle off chat history in `Settings` > `Chats` to prevent chat history from being created with new interactions.

- ğŸ”„ **Regeneration History Access**: Easily revisit and explore your entire regeneration history.

- ğŸ“¬ **Archive Chats**: Effortlessly store away completed conversations you've had with models for future reference or interaction, maintaining a tidy and clutter-free chat interface.

- ğŸ—ƒï¸ **Archive All Chats**: This feature allows you to quickly archive all of your chats at once.

- ğŸ“¦ **Export All Archived Chats as JSON**: This features enables users to easily export all their archived chats in a single JSON file, which can be used for backup or transfer purposes.

- ğŸ“„ **Download Chats as JSON/PDF/TXT**: Easily download your chats individually in your preffered format of `.json`, `.pdf`, or `.txt` format.

- ğŸ“¤ğŸ“¥ **Import/Export Chat History**: Seamlessly move your chat data in and out of the platform via `Import Chats` and `Export Chats` options.

- ğŸ—‘ï¸ **Delete All Chats**: This option allows you to permanently delete all of your chats, ensuring a fresh start.

---

### ğŸ™ï¸ Voice & Accessibility

- ğŸ—£ï¸ **Voice Input Support**: Engage with your model through voice interactions; enjoy the convenience of talking to your model directly. Additionally, explore the option for sending voice input automatically after 3 seconds of silence for a streamlined experience.
 - Microphone access requires a secure connection over HTTPS for this feature to work.

- ğŸ˜Š **Emoji Call**: Toggle this feature on from the `Settings` > `Interface`, allowing LLMs to express emotions using emojis during voice calls for a more dynamic interaction.
 - Microphone access requires a secure connection over HTTPS for this feature to work.

- ğŸ™ï¸ **Hands-Free Voice Call Feature**: Initiate voice calls without needing to use your hands, making interactions more seamless.
 - Microphone access is required using a secure connection over HTTPS for this feature to work.

- ğŸ“¹ **Video Call Feature**: Enable video calls with supported vision models like LlaVA and GPT-4o, adding a visual dimension to your communications.
 - Both Camera & Microphone access is required using a secure connection over HTTPS for this feature to work.

- ğŸ‘† **Tap to Interrupt**: Stop the AIâ€™s speech during voice conversations with a simple tap on mobile devices, ensuring seamless control over the interaction.

- ğŸ”Š **Configurable Text-to-Speech Endpoint**: Customize your Text-to-Speech experience with configurable OpenAI-compatible endpoints for reading aloud LLM responses.

---

### ğŸ Code Execution

- ğŸš€ **Versatile, UI-Agnostic, OpenAI-Compatible Plugin Framework**: Seamlessly integrate and customize [Open WebUI Pipelines](https://github.com/open-webui/pipelines) for efficient data processing and model training, ensuring ultimate flexibility and scalability.

-  ğŸ› ï¸ **Native Python Function Calling**: Access the power of Python directly within Open WebUI with native function calling. Easily integrate custom code to build unique features like custom RAG pipelines, web search tools, and even agent-like actions via a built-in code editor to seamlessly develop and integrate function code within the `Tools` and `Functions` workspace.

- ğŸ **Python Code Execution**: Execute Python code locally in the browser via Pyodide with a range of libraries supported by Pyodide.

- ğŸŒŠ **Mermaid Rendering**: Create visually appealing diagrams and flowcharts directly within Open WebUI using the [Mermaid Diagramming and charting tool](https://mermaid.js.org/intro/), which supports Mermaid syntax rendering.

---

### ğŸ”’ Integration & Security

- âœ¨ **Multiple OpenAI-Compatible API Support**: Seamlessly integrate and customize various OpenAI-compatible APIs, enhancing the versatility of your chat interactions.

- ğŸ”‘ **Simplified API Key Management**: Easily generate and manage secret keys to leverage Open WebUI with OpenAI libraries, streamlining integration and development.

- ğŸŒ **HTTP/S Proxy Support**: Configure network settings easily using the `http_proxy` or `https_proxy` environment variable. These variables, if set, should contain the URLs for HTTP and HTTPS proxies, respectively.

- ğŸŒğŸ”— **External Ollama Server Connectivity**: Seamlessly link to an external Ollama server hosted on a different address by configuring the environment variable.

- ğŸ›¢ï¸ **External Database Support**: Seamlessly connect to custom SQLite or Postgres databases using the `DATABASE_URL` environment variable.

- ğŸŒğŸ—£ï¸ **External Speech-to-Text Support**: Enjoy enhanced flexibility with the addition of external Speech-To-Text (`STT`) services, allowing you to choose your preferred provider for seamless interaction.

- ğŸŒ **Remote ChromaDB Support**: Expand your database capabilities with the ability to connect to remote ChromaDB servers.

- ğŸ”€ **Multiple Ollama Instance Load Balancing**: Effortlessly distribute chat requests across multiple Ollama instances for enhanced performance and reliability.

---

### ğŸ‘‘ Administration

- ğŸ‘‘ **Super Admin Assignment**: Automatically assign the first sign up as a super admin with an unchangeable role that cannot be modified by anyone else, not even other admins.

- ğŸ›¡ï¸ **Granular User Permissions**: Restrict user actions and access with customizable role-based permissions, ensuring that only authorized individuals can perform specific tasks.

- ğŸ‘¥ **Multi-User Management**: Seamlessly manage multiple users through our intuitive admin panel with pagination, streamlining user administration and simplifying user life-cycle management.

- ğŸ”§ **Admin Panel**: Streamlined user management with options to add users directly or in bulk via CSV import, making user on-boarding and management efficient.

- ğŸ‘¥ **Active Users Indicator**: Track active users count and which models are actively being used by whom to help you gauge when performance might be impacted due to a high number of users.

- ğŸ”’ **Default Sign-Up Role**: Set the default role for new sign-ups to `pending`, `user`, or `admin`, providing flexibility in managing user permissions and access levels for new users.

- ğŸ”’ **Prevent New Sign Ups**: Ability to disable new user sign-ups, restricting access to the platform and maintaining a fixed number of users.

- ğŸ”’ **Prevent Chat Deletion**: Ability for admins to toggle a setting that prevents all users from deleting their chat messages, ensuring that all chat messages are retained for audit or compliance purposes.

- ğŸ”— **Webhook Integration**: Subscribe to new user sign-up events via webhook (compatible with `Discord`, `Google Chat` and `Microsoft Teams`), providing real-time notifications and automation capabilities.

- ğŸ“£ **Configurable Notification Banners**: Admins can create customizable banners with persistence in config.json, featuring options for content, background color (`info`, `warning`, `error`, or `success`), and dismissibility. These banners are only accessible to logged-in users, ensuring sensitive information remains private.

- ğŸ›¡ï¸ **Model Whitelisting**: Enhance security and access control by allowing admins to whitelist models for users with the `user` role, ensuring that only authorized models can be accessed.

- ğŸ”‘ **Admin Control for Community Sharing**: Admins can enable or disable community sharing for all users via a toggle in `Admin Panel` > `Settings`. This toggle allows admins to manage accessibility and privacy, ensuring a secure environment. Admins can choose to enable or disable the `Share on Community` button for all users, controlling community engagement and collaboration.

- ğŸ“§ **Trusted Email Authentication**: Authenticate using a trusted email header, adding an extra layer of security and authentication to protect your Open WebUI instance.

- ğŸ”’ **Backend Reverse Proxy Support**: Bolster security through direct communication between Open WebUI backend and Ollama. This key feature eliminates the need to expose Ollama over LAN. Requests made to the `/ollama/api` route from Opeb WebUI are seamlessly redirected to Ollama from the backend, enhancing overall system security.

- ğŸ”’ **Authentication**: Open WebUI does not natively support federated authentication schemes such as SSO, OAuth, SAML, or OIDC. However, it can be configured to delegate authentication to an authenticating reverse proxy, effectively achieving a Single Sign-On (`SSO`) experience. This setup allows you to centralize user authentication and management, enhancing security and user convenience. By integrating Open WebUI with an authenticating reverse proxy, you can leverage existing authentication systems and streamline user access to Open WebUI. For more information on configuring this feature, please refer to the [Federated Authentication Support](https://docs.openwebui.com/tutorial/sso).

- ğŸ”“ **Optional Authentication**: Enjoy the flexibility of disabling authentication by setting `WEBUI_AUTH` to `False`, ideal for fresh installations without existing users and demo purposes.


---

### ğŸ“„ Swagger Documentation

-  ğŸ“„  **Comprehensive Swagger documentation**: providing detailed information on endpoints, parameters, and responses. This feature streamlines API integration and development, ensuring seamless communication between Open WebUI and external systems.

    | App  | Docs Path           |
    |--------------|---------------------|
    | WebUI    | /api/v1/docs        | 
    | Ollama   | /ollama/docs        |
    | OpenAI   | /openai/api/docs    | 
    | Images   | /images/api/v1/docs | 
    | Audio    | /audio/api/v1/docs  |
    | RAG      | /rag/api/v1/docs    |
