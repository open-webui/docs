---
sidebar_position: 1
title: "ğŸ› ï¸ Tools & Functions"
---

# ğŸ› ï¸ Tools & Functions

Imagine you've just stumbled upon Open WebUI, or maybe you're already using it, but you're a bit lost with all the talk about "Tools", "Functions", and "Pipelines". Everything sounds like some mysterious tech jargon, right? No worries! Let's break it down piece by piece, super clearly, step by step. By the end of this, you'll have a solid understanding of what these terms mean, how they work, and why know it's not as complicated as it seems.

## TL;DR

- **Tools** extend the abilities of LLMs, allowing them to collect real-world, real-time data like weather, stock prices, etc.
- **Functions** extend the capabilities of the Open WebUI itself, enabling you to add new AI model support (like Anthropic or Vertex AI) or improve usability (like creating custom buttons or filters).
- **Pipelines** are more for advanced users who want to transform Open WebUI features into API-compatible workflowsâ€”mainly for offloading heavy processing.

Getting started with Tools and Functions is easy because everythingâ€™s already built into the core system! You just **click a button** and **import these features directly from the community**, so thereâ€™s no coding or deep technical work required.

## What are "Tools" and "Functions"?

Let's start by thinking of **Open WebUI** as a "base" software that can do many tasks related to using Large Language Models (LLMs). But sometimes, you need extra features or abilities that don't come *out of the box*â€”this is where **tools** and **functions** come into play.

### Tools

**Tools** are an exciting feature because they allow LLMs to do more than just process text. They provide **external abilities** that LLMs wouldn't otherwise have on their own.

#### Example of a Tool:

Imagine you're chatting with an LLM and you want it to give you the latest weather update or stock prices in real time. Normally, the LLM can't do that because it's just working on pre-trained knowledge. This is where **tools** come in!

- **Tools are like plugins** that the LLM can use to gather **real-world, real-time data**. So, with a "weather tool" enabled, the model can go out on the internet, gather live weather data, and display it in your conversation.

Tools are essentially **abilities** youâ€™re giving your AI to help it interact with the outside world. By adding these, the LLM can "grab" useful information or perform specialized tasks based on the context of the conversation.

#### Examples of Tools (extending LLMâ€™s abilities):
1. **Real-time weather predictions** ğŸ›°ï¸.
2. **Stock price retrievers** ğŸ“ˆ.
3. **Flight tracking information** âœˆï¸.

### Functions

While **tools** are used by the AI during a conversation, **functions** help extend or customize the capabilities of Open WebUI itself. Imagine tools are like adding new ingredients to a dish, and functions are the process you use to control the kitchen! ğŸšª

#### Let's break that down: 

- **Functions** give you the ability to tweak or add **features** inside **Open WebUI** itself.
- Youâ€™re not giving new abilities to the LLM, but instead, youâ€™re extending the **interface, behavior, or logic** of the platform itself!

For instance, maybe you want to:
1. Add a new AI model like **Anthropic** to the WebUI.
2. Create a custom button in your toolbar that performs a frequently used command.
3. Implement a better **filter** function that catches inappropriate or **spammy messages** from the incoming text.

Without functions, these would all be out of reach. But with this framework in Open WebUI, you can easily extend these features!

### Summary of Differences:
- **Tools** are things that allow LLMs to **do more things** outside their default abilities (such as retrieving live info or performing custom tasks based on external data).
- **Functions** help the WebUI itself **do more things**, like adding new AI models or creating smarter ways to filter data.

Both are designed to be **pluggable**, meaning you can easily import them into your system with just one click from the community! ğŸ‰ You wonâ€™t have to spend hours coding or tinkering with them.

## What are Pipelines?

And then, we have **Pipelines**â€¦ Hereâ€™s where things start to sound pretty technicalâ€”but donâ€™t despair.

**Pipelines** are part of an Open WebUI initiative focused on making every piece of the WebUI **inter-operable with OpenAIâ€™s API system**. Essentially, they extend what both **Tools** and **Functions** can already do, but now with even more flexibility. They allow you to turn features into OpenAI API-compatible formats. ğŸ§ 

### But hereâ€™s the thingâ€¦ 

You likely **won't need** pipelines unless you're dealing with super-advanced setups.

- **Who are pipelines for?** Typically, **experts** or people running more complicated use cases.
- **When do you need them?** If you're trying to offload processing from your primary Open WebUI instance to a different machine (so you donâ€™t overload your primary system).
  
In most cases, as a beginner or even an intermediate user, you wonâ€™t have to worry about pipelines. Just focus on enjoying the benefits that **tools** and **functions** bring to your Open WebUI experience!

## Want to Try? ğŸš€

Jump into Open WebUI, head over to the community section, and try importing a tool like **weather updates** or maybe adding a new feature to the toolbar with a function. Exploring these tools will show you how powerful and flexible Open WebUI can be!

ğŸŒŸ There's always more to learn, so stay curious and keep experimenting!