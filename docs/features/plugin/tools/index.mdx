---
sidebar_position: 1
title: "Tools"
---

# What are Tools?

‚öôÔ∏è Tools are the various ways you can extend an LLM's capabilities beyond simple text generation. When enabled, they allow your chatbot to do amazing things ‚Äî like search the web, scrape data, generate images, talk back using AI voices, and more.

Because there are several ways to integrate "Tools" in Open WebUI, it's important to understand which type you are using.

---

## Tooling Taxonomy: Which "Tool" are you using?

üß© Users often encounter the term "Tools" in different contexts. Here is how to distinguish them:

| Type | Location in UI | Best For... | Source |
| :--- | :--- | :--- | :--- |
| **Native Features** | Admin/Settings | Core platform functionality | Built-in to Open WebUI |
| **Workspace Tools** | `Workspace > Tools` | User-created or community Python scripts | [Community Library](https://openwebui.com/search) |
| **Native MCP (HTTP)** | `Settings > Connections` | Standard MCP servers reachable via HTTP/SSE | External MCP Servers |
| **MCP via Proxy (MCPO)** | `Settings > Connections` | Local stdio-based MCP servers (e.g., Claude Desktop tools) | [MCPO Adapter](https://github.com/open-webui/mcpo) |
| **OpenAPI Servers** | `Settings > Connections` | Standard REST/OpenAPI web services | External Web APIs |

### 1. Native Features (Built-in)
These are deeply integrated into Open WebUI and generally don't require external scripts.
- **Web Search**: Integrated via engines like SearXNG, Google, or Tavily.
- **URL Fetching**: Extract text content directly from websites using `#` or native tools.
- **Image Generation**: Integrated with DALL-E, ComfyUI, or Automatic1111.
- **Memory**: The ability for models to remember facts about you across chats.
- **RAG (Knowledge)**: The ability to query uploaded documents (`#`).

In [**Native Mode**](#built-in-system-tools-native-mode), these features are exposed as **Tools** that the model can call independently.

### 2. Workspace Tools (Custom Plugins)
These are **Python scripts** that run directly within the Open WebUI environment.
- **Capability**: Can do anything Python can do (web scraping, complex math, API calls).
- **Access**: Managed via the `Workspace` menu. 
- **Safety**: Always review code before importing, as these run on your server.
- **‚ö†Ô∏è Security Warning**: Normal or untrusted users should **not** be given permission to access the Workspace Tools section. This access allows a user to upload and execute arbitrary Python code on your server, which could lead to a full system compromise.

### 3. MCP (Model Context Protocol)

üîå MCP is an open standard that allows LLMs to interact with external data and tools.
- **Native HTTP MCP**: Open WebUI can connect directly to any MCP server that exposes an HTTP/SSE endpoint.
- **MCPO (Proxy)**: Most community MCP servers use `stdio` (local command line). To use these in Open WebUI, you use the [**MCPO Proxy**](../../plugin/tools/openapi-servers/mcp.mdx) to bridge the connection.

### 4. OpenAPI / Function Calling Servers
Generic web servers that provide an OpenAPI (`.json` or `.yaml`) specification. Open WebUI can ingest these specs and treat every endpoint as a tool.

---

## How to Install & Manage Workspace Tools

üì¶ Workspace Tools are the most common way to extend your instance with community features.

1. Go to [Community Tool Library](https://openwebui.com/search)
2. Choose a Tool, then click the **Get** button.
3. Enter your Open WebUI instance‚Äôs URL (e.g. `http://localhost:3000`).
4. Click **Import to WebUI**.

:::warning Safety Tip
Never import a Tool you don‚Äôt recognize or trust. These are Python scripts and might run unsafe code on your host system. **Crucially, ensure you only grant "Tool" permissions to trusted users**, as the ability to create or import tools is equivalent to the ability to run arbitrary code on the server.
:::

---

## How to Use Tools in Chat

üîß Once installed or connected, here‚Äôs how to enable them for your conversations:

### Option 1: Enable on-the-fly (Specific Chat)
While chatting, click the **‚ûï (plus)** icon in the input area. You‚Äôll see a list of available Tools ‚Äî you can enable them specifically for that session.

### Option 2: Enable by Default (Global/Model Level)
1. Go to **Workspace ‚û°Ô∏è Models**.
2. Choose the model you‚Äôre using and click the ‚úèÔ∏è edit icon.
3. Scroll to the **Tools** section.
4. ‚úÖ Check the Tools you want this model to always have access to by default.
5. Click **Save**.

You can also let your LLM auto-select the right Tools using the [**AutoTool Filter**](https://openwebui.com/f/hub/autotool_filter/).

---

## Tool Calling Modes: Default vs. Native

Open WebUI offers two distinct ways for models to interact with tools. Choosing the right mode depends on your model's capabilities and your performance requirements.

### üü° Default Mode (Prompt-based)
In Default Mode, Open WebUI manages tool selection by injecting a specific prompt template that guides the model to output a tool request. 
- **Compatibility**: Works with **practically any model**, including older or smaller local models that lack native function-calling support.
- **Flexibility**: Highly customizable via prompt templates.
- **Caveat**: Can be slower (requires extra tokens) and less reliable for complex, multi-step tool chaining.

### üü¢ Native Mode (System Function Calling)
Native Mode leverages the model's built-in capability to handle tool definitions and return structured tool calls (JSON). This is the **recommended mode** for high-performance agentic workflows.

#### Why use Native Mode?
- **Speed & Efficiency**: Lower latency as it avoids bulky prompt-based tool selection.
- **Reliability**: Higher accuracy in following tool schemas.
- **Multi-step Chaining**: Essential for **Agentic Research** and **Interleaved Thinking** where a model needs to call multiple tools in succession.

#### How to Enable Native Mode
Native Mode can be enabled at two levels:

1.  **Global/Administrator Level (Recommended)**:
    *   Navigate to **Admin Panel > Settings > Models**.
    *   Scroll to **Model Specific Settings** for your target model.
    *   Under **Advanced Parameters**, find the **Function Calling** dropdown and select `Native`.
2.  **Per-Chat Basis**:
    *   Inside a chat, click the ‚öôÔ∏è **Chat Controls** icon.
    *   Go to **Advanced Params** and set **Function Calling** to `Native`.

![Chat Controls](/images/features/plugin/tools/chat-controls.png)



#### Model Requirements & Caveats
- **Recommended Models**: High-tier models like **GPT-5**, **Claude 4.5 Sonnet**, **Gemini 3 Flash**, and **MiniMax M2.1** excel in Native Mode.
- **Local Model Warning**: While large local models (e.g., Qwen 3 32B) support native tool calling, **small local models** often struggle with Native Mode. They may produce malformed JSON or fail to follow the strict state management required for sequential calls. For these models, **Default Mode** is usually more reliable.

| Feature | Default Mode | Native Mode |
|:---|:---|:---|
| **Latency** | Medium/High | Low |
| **Model Compatibility** | Universal | Requires Tool-Calling Support |
| **Logic** | Prompt-based (Open WebUI) | Model-native (API/Ollama) |
| **Complex Chaining** | ‚ö†Ô∏è Limited | ‚úÖ Excellent |

### Built-in System Tools (Native Mode)

üõ†Ô∏è When **Native Mode** is enabled, Open WebUI automatically injects powerful system tools based on the features toggled for the chat. This unlocks "Agentic" behaviors where models (like GPT-5, Claude 4.5, or MiniMax M2.1) can perform multi-step research or manage user memory dynamically.

| Tool | Purpose | Requirements |
|------|---------|--------------|
| **Search & Web** | | |
| `web_search` | Performs a search using the configured Search Engine. | `ENABLE_WEB_SEARCH` enabled. |
| `fetch_url` | Visits a URL and extracts text content via the Web Loader. | Part of Web Search feature. |
| **Image Gen** | | |
| `generate_image` | Generates a new image based on a prompt (supports `steps`). | `ENABLE_IMAGE_GENERATION` enabled. |
| `edit_image` | Edits an existing image based on a prompt and URL. | `ENABLE_IMAGE_EDIT` enabled.|
| **Memory** | | |
| `memory_query` | Searches the user's personal memory/personalization bank. | Memory feature enabled. |
| `memory_add` | Stores a new fact in the user's personalization memory. | Memory feature enabled. |
| **Notes** | | |
| `search_notes` | Search the user's notes by title and content. | `ENABLE_NOTES` enabled. |
| `view_note` | Get the full markdown content of a specific note. | `ENABLE_NOTES` enabled. |
| `write_note` | Create a new private note for the user. | `ENABLE_NOTES` enabled. |
| `replace_note_content` | Update an existing note's content or title. | `ENABLE_NOTES` enabled. |
| **Chat History** | | |
| `search_chats` | Search across the user's previous conversation history. | Always available. |
| `view_chat` | Retrieve the full message history of a specific previous chat. | Always available. |
| **Channels** | | |
| `search_channels` | Find public or accessible channels by name/description. | `ENABLE_CHANNELS` enabled. |
| `search_channel_messages` | Search for specific messages inside accessible channels. | `ENABLE_CHANNELS` enabled. |
| `view_channel_message` | View a specific message or its details in a channel. | `ENABLE_CHANNELS` enabled. |
| `view_channel_thread` | View a full message thread/replies in a channel. | `ENABLE_CHANNELS` enabled. |
| **Time Tools** | | |
| `get_current_timestamp` | Get the current UTC Unix timestamp and ISO date. | Always available. |
| `calculate_timestamp` | Calculate relative timestamps (e.g., "3 days ago"). | Always available. |

**Why use these?** It allows for **Deep Research** (searching multiple times), **Contextual Awareness** (looking up previous chats or notes), **Dynamic Personalization** (saving facts), and **Precise Automation** (generating content based on existing notes).

### Interleaved Thinking {#interleaved-thinking}

üß† When using **Native Mode**, high-tier models can engage in **Interleaved Thinking**. This is a powerful "Thought ‚Üí Action ‚Üí Thought ‚Üí Action ‚Üí Thought ‚Üí ..." loop where the model can reason about a task, execute one or more tools, evaluate the results, and then decide on its next move.

This is fundamentally different from a single-shot tool call. In an interleaved workflow, the model follows a cycle:
1.  **Reason**: Analyze the user's intent and identify information gaps.
2.  **Act**: Call a tool (e.g., `web_search` and `fetch_url`).
3.  **Think**: Read the tool's output and update its internal understanding.
4.  **Iterate**: If the answer isn't clear, call another tool (e.g., `fetch_url` to read a specific page) or refine the search.
5.  **Finalize**: Only after completing this "Deep Research" cycle does the model provide a final, grounded answer.

This behavior is what transforms a standard chatbot into an **Agentic AI** capable of solving complex, multi-step problems autonomously.

---

---

## üöÄ Summary & Next Steps

Tools bring your AI to life by giving it hands to interact with the world.
- **Browse Tools**: [openwebui.com/search](https://openwebui.com/search)
- **Advanced Setup**: Learn more about [MCP Support](./openapi-servers/mcp.mdx)
- **Development**: [Writing your own Custom Toolkits](./development.mdx)
